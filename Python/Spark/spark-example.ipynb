{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize spark context\n",
    "Topics not covered with an example:\n",
    "* Cahce: Save RDD for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark context already exists, use the old one\n"
     ]
    }
   ],
   "source": [
    "#Import `pyspark` and create `SparkContext`\n",
    "from pyspark import SparkContext\n",
    "\n",
    "#If spark context does not exist yet\n",
    "try:\n",
    "    sc\n",
    "except NameError:\n",
    "    sc = None\n",
    "    \n",
    "if sc is None:\n",
    "    sc = SparkContext(\"local\", \"test app\")\n",
    "    print(\"Created spark context\")\n",
    "else:\n",
    "    print(\"Spark context already exists, use the old one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create RDDs for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a list of random words\n",
    "word_list = [\n",
    "    \"alpha\",\n",
    "    \"bravo\",\n",
    "    \"charlie\",\n",
    "    \"delta\",\n",
    "    \"echo\",\n",
    "    \"foxtrot\",\n",
    "    \"alpha and bravo\",\n",
    "    \"charlie and alpha\"\n",
    "]\n",
    "\n",
    "#List to RDD\n",
    "word_rdd = sc.parallelize(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a list of numbers\n",
    "num_list = [1,2,3,4,5,6]\n",
    "\n",
    "#List to RDD\n",
    "num_rdd = sc.parallelize(num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines with a: 1, lines with e: 3\n"
     ]
    }
   ],
   "source": [
    "#Name of file to read\n",
    "file_name = \"test-file.txt\"\n",
    "\n",
    "#Read the text file\n",
    "file_data = sc.textFile(file_name).cache()\n",
    "\n",
    "#Count number of lines having a letter\n",
    "num_a = file_data.filter(lambda s: 'a' in s).count()\n",
    "num_e = file_data.filter(lambda s: 'e' in s).count()\n",
    "\n",
    "#Print results\n",
    "msg = \"Lines with a: {}, lines with e: {}\".format(num_a, num_e)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in RDD: 8\n"
     ]
    }
   ],
   "source": [
    "#Count words in RDD\n",
    "cnt = word_rdd.count()\n",
    "\n",
    "#Print results\n",
    "print(\"Number of words in RDD: {}\".format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All items in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha',\n",
       " 'bravo',\n",
       " 'charlie',\n",
       " 'delta',\n",
       " 'echo',\n",
       " 'foxtrot',\n",
       " 'alpha and bravo',\n",
       " 'charlie and alpha']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    #Prints to console, not on notebook\n",
    "    print(x)\n",
    "    \n",
    "#For each\n",
    "word_rdd.foreach(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitered RDD: ['alpha', 'alpha and bravo', 'charlie and alpha']\n"
     ]
    }
   ],
   "source": [
    "#Set up the filter: Words containing 'alpha'\n",
    "words_filter = word_rdd.filter(lambda x: 'alpha' in x)\n",
    "\n",
    "#Get the list of filtered items\n",
    "filtered = words_filter.collect()\n",
    "\n",
    "#Print results\n",
    "print(\"Fitered RDD: {}\".format(filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map\n",
    "A new RDD is returned by applying a function to each element in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key value pair: ['ALPHA', 'BRAVO', 'CHARLIE', 'DELTA', 'ECHO', 'FOXTROT', 'ALPHA AND BRAVO', 'CHARLIE AND ALPHA']\n"
     ]
    }
   ],
   "source": [
    "#Set up the mapper: Words to uppercase\n",
    "words_map = word_rdd.map(lambda x: x.upper())\n",
    "\n",
    "#Map and return all items\n",
    "mapping = words_map.collect()\n",
    "\n",
    "#Print results\n",
    "print(\"Key value pair: {}\".format(mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce\n",
    "**1. step**\n",
    "* Take the first two items as input\n",
    "* Perform the reduce function to get the output\n",
    "\n",
    "**All other steps** \n",
    "* Take the current item and the  previous output as input\n",
    "* Perform the reduce function to get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of all elements: 21\n"
     ]
    }
   ],
   "source": [
    "#A custom reducer function that takes two numbers and sums thems up\n",
    "def add_reducer(a, b):\n",
    "    return a+b\n",
    "\n",
    "#Set up the reducer: Add two items to each other\n",
    "adding = num_rdd.reduce(add_reducer)\n",
    "#Print results\n",
    "print(\"Sum of all elements: {}\".format(adding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Join RDD: [('hadoop', (4, 5)), ('spark', (1, 2))]\n"
     ]
    }
   ],
   "source": [
    "#First RDD\n",
    "x = sc.parallelize([(\"spark\", 1), (\"hadoop\", 4)])\n",
    "\n",
    "#Another RDD to join\n",
    "y = sc.parallelize([(\"spark\", 2), (\"hadoop\", 5)])\n",
    "\n",
    "#Join RDDs\n",
    "joined = x.join(y)\n",
    "\n",
    "#Get all items\n",
    "joined_items = joined.collect()\n",
    "\n",
    "#Print results\n",
    "print(\"Joined RDD: {}\".format(joined_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
